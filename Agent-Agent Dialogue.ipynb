{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = 'YOUR OPENAI API KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "# create a folder to store the conversations if it does not exist\n",
    "path = 'ChatGPT_conversations'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "# use environment variables for API key\n",
    "timestamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'model': 'gpt-4', # or switch for cheaper dialogue to gpt-3.5-turbo \n",
    "    'temperature': 1, # this will lead to create responses that are more creative\n",
    "    'max_tokens': 150\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional cell, run if request is outdated\n",
    "#pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_request(messages):\n",
    "    completion = openai.ChatCompletion.create( \n",
    "        messages=messages, \n",
    "        **settings)\n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set conditions of agents and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert & Ernie example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent1 = \"You are serious, studious and a world-weary foil. You get annoyed quickly with playful people. Don't be considerate. Try to use 1 to 3 sentences.\"\n",
    "Agent2 = \"You are a na√Øve troublemaker and don't take yourself too seriously and enjoy having a good time. Don't be considerate. Try to use 1 to 3 sentences.\"\n",
    "Context = \"a discussion about inheritance tax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Socrates and Aristotle example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent1 = \"Behave as Socrates. Answer in 1 to 3 sentences.\"\n",
    "Agent2 = \"Behave as Aristotle. Answer in 1 to 3 sentences.\"\n",
    "Context = \"Chairs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising prompts (rerun each cell from here every new dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages1=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": Agent1 \n",
    "    }]\n",
    "messages2=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": Agent2 \n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"You are talking about \" + Context + \". \" + \" What do you say?\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Response generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first generation\n",
    "def first_generation():\n",
    "    response = open_ai_request(messages2)\n",
    "    print(f'Agent2: {response}')\n",
    "    messages2.append({\"role\": \"assistant\", \"content\": response})\n",
    "    response1 = f\"Someone said the following: {response}. How do you react?\"\n",
    "    #response1 = f\"You are talking about {Context} . Someone said the following: {response}. What do you say? {Agent2_prompt}\"\n",
    "    messages1.append({\"role\": \"user\", \"content\": response1})\n",
    "    return messages1, messages2\n",
    "\n",
    "# Generation of first agent\n",
    "def agent1_generation():\n",
    "    response = open_ai_request(messages1)\n",
    "    print(f'Agent1: {response}')\n",
    "    messages1.append({\"role\": \"assistant\", \"content\": response})\n",
    "    messages2.append({\"role\": \"user\", \"content\": response})\n",
    "    return messages1, messages2\n",
    "\n",
    "# Generation of second agent\n",
    "def agent2_generation():\n",
    "    response = open_ai_request(messages2)\n",
    "    print(f'Agent2: {response}')\n",
    "    messages1.append({\"role\": \"user\", \"content\": response})\n",
    "    messages2.append({\"role\": \"assistant\", \"content\": response})\n",
    "    return messages1, messages2\n",
    "# Ik heb de print agent 1 en 2 nu omgedraaid zodat ie wel overeenkomt vgm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running dialogue 5 turns (turns can be adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent2: A chair, in its most rudimentary form, serves as an instrument for rest, a feat achieved by its design that accommodates the human form. In all of its complexity, a chair reflects the intersection between necessity and art, embodying function and beauty. The difference in chairs illuminates the variety of cultures, needs, and the evolution of human creativity.\n",
      "Agent1: Indeed, you've unraveled the essence of chairs beautifully. Just as you elucidated, objects around us, not limited to chairs, unveil the profound interplay between necessity and aesthetics, illuminating the diverse fabric of cultures and evolution of creativity in mankind. In such perspectives, do we not discover the proof of human intellect and its infinite capacity for creativity?\n",
      "Agent2: Precisely, it is through the creation and use of objects such as chairs that we truly perceive man's intellectual capacity and ceaseless creativity. This unending cycle of innovation and adaptation highlights our ability to shape the world around us. Thus, the objects we create, though seemingly mundane, are a testament to the profundity of human intellect.\n",
      "Agent1: Indeed, you see with clarity. The ostensibly mundane is often a reflection of the extraordinary. For in the design and use of every object, we see a pattern of thought, a problem identified and solved, marking the echo of human intellect across the echo of time. Every invention, no matter how simple, tells a story of our collective evolution and creativity.\n",
      "Agent2: That is a profound truth, indeed. Every creation, no matter how commonplace, signifies mankind's innate curiosity and enduring pursuit of refinement. Each object, then, does not merely fulfill a practical need, but becomes a testament to our intellectual evolution. Through understanding this we are connected, in a tangible way, to the continuous flow of mankind's unfolding story.\n"
     ]
    }
   ],
   "source": [
    "conversation_rounds = 5\n",
    "round_counter = 0\n",
    "for i in range(conversation_rounds):\n",
    "    round_counter += 1 \n",
    "    if i == 0:\n",
    "        first_generation()\n",
    "    else:\n",
    "        if i % 2 == 0:\n",
    "            agent2_generation()\n",
    "        else:\n",
    "            agent1_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend dialogue (5 turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_rounds = 5\n",
    "\n",
    "for i in range(more_rounds):\n",
    "    round_counter += 1\n",
    "    if round_counter % 2 == 0:\n",
    "        agent1_generation()\n",
    "    else:\n",
    "        agent2_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_rounds = 5\n",
    "\n",
    "for i in range(more_rounds):\n",
    "    round_counter += 1\n",
    "    if round_counter % 2 == 0:\n",
    "        agent1_generation()\n",
    "    else:\n",
    "        agent2_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclude conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclude_agent1():\n",
    "    last_content1 = messages1[-1]['content']\n",
    "    response1 = f\"The last thing your conversation partner said was the following: ' {last_content1} '  Conclude the conversation. To what extent do you agree with the mentioned arguments in the conversation?\"\n",
    "    messages1[-1]['content'] = response1\n",
    "    response = open_ai_request(messages1)\n",
    "    print(f'Agent1: {response}')\n",
    "    messages1.append({\"role\": \"assistant\", \"content\": response})\n",
    "    messages2.append({\"role\": \"user\", \"content\": \"Conclude the conversation. To what extent do you agree with the mentioned arguments in the conversation?\"})\n",
    "\n",
    "    response = open_ai_request(messages2)\n",
    "    print(f'Agent2: {response}')\n",
    "    #messages1.append({\"role\": \"user\", \"content\": response})\n",
    "    messages2.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    return messages1, messages2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conclude_agent2():\n",
    "    last_content2 = messages2[-1]['content']\n",
    "    response2 = f\"The last thing your conversation partner said was the following: ' {last_content2} ' Conclude the conversation. To what extent do you agree with the mentioned arguments in the conversation?\"\n",
    "    messages2[-1]['content'] = response2\n",
    "    response = open_ai_request(messages2)\n",
    "    print(f'Agent2: {response}')\n",
    "    messages2.append({\"role\": \"assistant\", \"content\": response})\n",
    "    messages1.append({\"role\": \"user\", \"content\": \"Conclude the conversation. To what extent do you agree with the mentioned arguments in the conversation?\"})\n",
    "    \n",
    "    response = open_ai_request(messages1)\n",
    "    print(f'Agent1: {response}')\n",
    "    messages1.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    return messages1, messages2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent1: You have indeed reflected the nature of human creation with wisdom. Our everyday objects, simple as they may seem, possess a depth that links us to the ongoing tapestry of human history and evolution. Let us never underestimate these humble tokens of curiosity and refinement; through them, we discern humanity's ceaseless quest for knowledge, illuminating our connection to the infinite story of mankind.\n",
      "Agent2: I stand in full agreement. What we create, more often than not, is a reflection of our intellectual capabilities. The objects we fashion, from the simple to the complex, echo our thoughts, problem-solving abilities, and creativity. They stand as a testament to our collective progress, not just in terms of technology, but in terms of our refined understanding of the world around us.\n"
     ]
    }
   ],
   "source": [
    "if round_counter % 2 == 0:\n",
    "    conclude_agent2()\n",
    "else:\n",
    "    conclude_agent1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
